{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we start, let's start downloading the data\n",
    "\n",
    "The code in the following cell checks whether you have the [data](https://osf.io/u9sqa/), and if you don't, it starts downloading it. \n",
    "\n",
    "If you're running this notebook locally or using mybinder, then you will need to download the data. \n",
    "\n",
    "If you're running it using binder hosted on neurolibre, then you already have access to the data on neurolibre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "DIR=$\"../data/nimare_tutorial/\"\n",
    "if [ -d \"$DIR\" ]; then\n",
    "    echo \"$DIR exists.\"\n",
    "else \n",
    "    mkdir -p $DIR;\n",
    "    pip install osfclient\n",
    "    osf -p u9sqa clone  $DIR;\n",
    "    echo \"Created $DIR and downloaded the data\";\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHBM 2021 NiMARE tutorial\n",
    "\n",
    "## What is NiMARE?\n",
    "\n",
    "![NiMARE banner](images/nimare_banner.png)\n",
    "\n",
    "[NiMARE](https://nimare.readthedocs.io/en/latest/) is a Python library for performing neuroimaging meta-analyses and related analyses, like automated annotation and functional decoding. The goal of NiMARE is to centralize and standardize implementations of common meta-analytic tools, so that researchers can use whatever tool is most appropriate for a given research question.\n",
    "\n",
    "There are already a number of tools for neuroimaging meta-analysis:\n",
    "\n",
    "| <h2>Tool</h2> | <h2>Scope</h2> |\n",
    "| :------------ | :------------- |\n",
    "| <a href=\"https://brainmap.org\"><img src=\"images/brainmap_logo.png\" alt=\"BrainMap\" width=\"400\"/></a> | BrainMap includes a suite of applications for (1) searching its manually-annotated coordinate-based database, (2) adding studies to the database, and (3) running ALE meta-analyses. While search results can be extracted using its Sleuth app, access to the full database requires a collaborative use agreement. |\n",
    "| <a href=\"https://brainmap.org\"><img src=\"images/neurosynth_logo.png\" alt=\"Neurosynth\" width=\"200\"/></a> | Neurosynth provides (1) a large, automatically-extracted coordinate-based database, (2) a website for performing large-scale automated meta-analyses, and (3) a Python library for performing meta-analyses and functional decoding, mostly relying on a version of the MKDA algorithm. The Python library has been deprecated in favor of `NiMARE`. |\n",
    "| <a href=\"https://www.neurovault.org\"><img src=\"images/neurovault_logo.png\" alt=\"Neurovault\" width=\"200\"/></a> | Neurovault is a repository for sharing unthresholded statistical images, which can be used to search for images to use in image-based meta-analyses. Neurovault provides a tool for basic meta-analyses and an integration with Neurosynth's database for online functional decoding. |\n",
    "| <a href=\"https://www.sdmproject.com\"><img src=\"images/sdm_logo.png\" alt=\"SDM\" width=\"200\"/></a> | The Seed-based _d_ Mapping (SDM) app provides a graphical user interface and SPM toolbox for performing meta-analyses with the SDM algorithm, which supports a mix of coordinates and images. |\n",
    "| <a href=\"https://github.com/canlab/Canlab_MKDA_MetaAnalysis\"><img src=\"images/mkda_logo.png\" alt=\"MKDA\" width=\"200\"/></a> | The MATLAB-based MKDA toolbox includes functions for performing coordinate-based meta-analyses with the MKDA algorithm. |\n",
    "\n",
    "The majority of the above tools are (1) closed source, (2) based on graphical user interfaces, and/or (3) written in a programming language that is rarely used by neuroimagers, such as Java. \n",
    "\n",
    "In addition to these established tools, there are always interesting new methods that are described in journal articles, but which are never translated to a well-documented and supported implementation.\n",
    "\n",
    "NiMARE attempts to consolidate the different algorithms that are currently spread out across a range of tools (or which never make the jump from paper to tool), while still ensuring that the original tools and papers can be cited appropriately.\n",
    "\n",
    "## NiMARE's design philosophy\n",
    "\n",
    "NiMARE's API is designed to be similar to that of [`scikit-learn`](https://scikit-learn.org/stable/), in that most tools are custom classes. These classes follow the following basic structure:\n",
    "\n",
    "1. Initialize the class with general parameters\n",
    "```python\n",
    "cls = Class(param1, param2)\n",
    "```\n",
    "\n",
    "2. For Estimator classes, apply a `fit` method to a `Dataset` object to generate a `MetaResult` object\n",
    "```python\n",
    "result = cls.fit(dataset)\n",
    "```\n",
    "\n",
    "3. For Transformer classes, apply a `transform` method to an object to return a transformed version of that object\n",
    "\n",
    "    - An example transformer that accepts a `Dataset`:\n",
    "```python\n",
    "dataset = cls.transform(dataset)\n",
    "```\n",
    "    - A transformer that accepts a `MetaResult`:\n",
    "```python\n",
    "result = cls.transform(result)\n",
    "```\n",
    "\n",
    "## Stability and consistency\n",
    "\n",
    "NiMARE is currently in alpha development, so we appreciate any feedback or bug reports users can provide. Given its status, NiMARE's API may change in the future.\n",
    "\n",
    "Usage questions can be submitted to [Neurostars with the 'nimare' tag](https://neurostars.org/tag/nimare), while bug reports and feature requests can be submitted to [NiMARE's issue tracker](https://github.com/neurostuff/NiMARE/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals for this tutorial\n",
    "\n",
    "1. Working with NiMARE meta-analytic datasets\n",
    "1. Searching large datasets\n",
    "1. Performing coordinate-based meta-analyses\n",
    "1. Performing image-based meta-analyses\n",
    "1. Performing functional decoding using Neurosynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we'll need for this tutorial\n",
    "%matplotlib inline\n",
    "import json\n",
    "import os.path as op\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, reporting\n",
    "\n",
    "import nimare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = op.abspath(\"../data/nimare_tutorial/osfstorage/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of NiMARE datasets\n",
    "NiMARE relies on a specification for meta-analytic datasets named [NIMADS](https://github.com/neurostuff/NIMADS). Under NIMADS, meta-analytic datasets are stored as JSON files, with information about peak coordinates, _relative_ links to any unthresholded statistical images, metadata, annotations, and raw text.\n",
    "\n",
    "**NOTE**: NiMARE users generally do not need to create JSONs manually, so we won't go into that structure in this tutorial. Instead, users will typically have access to datasets stored in more established formats, like [Neurosynth](https://github.com/neurosynth/neurosynth-data) and [Sleuth](http://brainmap.org/sleuth/) files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading a dataset in NIMADS format, because this particular dataset contains both coordinates and images. This dataset is created from [Collection 1425 on NeuroVault](https://identifiers.org/neurovault.collection:1425), which contains [NIDM-Results packs](http://nidm.nidash.org/specs/nidm-results_130.html) for 21 pain studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset = nimare.dataset.Dataset(op.join(DATA_DIR, \"nidm_pain_dset.json\"))\n",
    "\n",
    "# In addition to loading the NIMADS-format JSON file,\n",
    "# we need to download the associated statistical images from NeuroVault,\n",
    "# for which NiMARE has a useful function.\n",
    "dset_dir = nimare.extract.download_nidm_pain(data_dir=DATA_DIR)\n",
    "\n",
    "# We then notify the Dataset about the location of the images,\n",
    "# so that the *relative paths* in the Dataset can be used to determine *absolute paths*.\n",
    "pain_dset.update_path(dset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NiMARE, datasets are stored in a special `Dataset` class. The `Dataset` class stores most relevant information as properties.\n",
    "\n",
    "The full list of identifiers in the Dataset is located in `Dataset.ids`. Identifiers are composed of two parts- a study ID and a contrast ID. Within the Dataset, those two parts are separated with a `-`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pain_dset.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most other information is stored in `pandas` DataFrames. The five DataFrame-based attributes are `Dataset.metadata`, `Dataset.coordinates`, `Dataset.images`, `Dataset.annotations`, and `Dataset.texts`.\n",
    "\n",
    "Each DataFrame contains at least three columns: `study_id`, `contrast_id`, and `id`, which is the combined `study_id` and `contrast_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other relevant attributes are `Dataset.masker` and `Dataset.space`.\n",
    "\n",
    "`Dataset.masker` is a [nilearn Masker object](https://nilearn.github.io/manipulating_images/masker_objects.html#), which specifies the manner in which voxel-wise information like peak coordinates and statistical images are mapped into usable arrays. Most meta-analytic tools within NiMARE accept a `masker` argument, so the Dataset's masker can be overridden in most cases.\n",
    "\n",
    "`Dataset.space` is just a string describing the standard space and resolution in which data within the Dataset are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also be saved to, and loaded from, binarized (pickled) files.\n",
    "\n",
    "We cannot save files on Binder, so here is the code we would use to save the pain Dataset:\n",
    "\n",
    "```python\n",
    "pain_dset.save(\"pain_dataset.pkl.gz\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a more common situation, where users want to use NiMARE on data from Neurosynth or a Sleuth file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and converting the Neurosynth dataset takes a long time, so we will use a pregenerated version of the dataset. However, here is the code we would use to download and convert the dataset from scratch:\n",
    "\n",
    "```python\n",
    "nimare.extract.fetch_neurosynth(\"data/\", unpack=True)\n",
    "ns_dset = nimare.io.convert_neurosynth_to_dataset(\n",
    "    \"data/database.txt\",\n",
    "    \"data/features.txt\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_dset = nimare.dataset.Dataset.load(op.join(DATA_DIR, \"neurosynth_dataset.pkl.gz\"))\n",
    "print(f\"There are {len(ns_dset.ids)} studies in the Neurosynth database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleuth_dset = nimare.io.convert_sleuth_to_dataset(op.join(DATA_DIR, \"sleuth_dataset.txt\"))\n",
    "print(f\"There are {len(sleuth_dset.ids)} studies in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching large datasets\n",
    "\n",
    "The `Dataset` class contains multiple methods for selecting subsets of studies within the dataset.\n",
    "\n",
    "One common approach is to search by \"labels\" or \"terms\" that apply to studies. In Neurosynth, labels are derived from term frequency within abstracts.\n",
    "\n",
    "The `slice` method creates a reduced `Dataset` from a list of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_ids = ns_dset.get_studies_by_label(\"Neurosynth_TFIDF__pain\", label_threshold=0.001)\n",
    "ns_pain_dset = ns_dset.slice(pain_ids)\n",
    "print(f\"There are {len(pain_ids)} studies labeled with 'pain'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MACM (meta-analytic coactivation modeling) analysis is generally performed by running a meta-analysis on studies with a peak in a region of interest, so Dataset includes two methods for searching based on the locations of coordinates: `Dataset.get_studies_by_coordinate` and `Dataset.get_studies_by_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_ids = ns_dset.get_studies_by_coordinate([[24, -2, -20]], r=6)\n",
    "sphere_dset = ns_dset.slice(sphere_ids)\n",
    "print(f\"There are {len(sphere_ids)} studies with at least one peak within 6mm of [24, -2, -20].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running meta-analyses\n",
    "\n",
    "## Coordinate-based meta-analysis\n",
    "\n",
    "Most coordinate-based meta-analysis algorithms are kernel-based, in that they convolve peaks reported in papers with a \"kernel\". Kernels are generally either binary spheres, as in multi-level kernel density analysis (MKDA), or 3D Gaussian distributions, as in activation likelihood estimation (ALE).\n",
    "\n",
    "NiMARE includes classes for different kernel transformers, which accept Datasets and generate the images resulting from convolving each study's peaks with the associated kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 5))\n",
    "\n",
    "# Apply different kernel transformers to the same Dataset\n",
    "kernels = [\n",
    "    nimare.meta.kernel.MKDAKernel(r=10),\n",
    "    nimare.meta.kernel.KDAKernel(r=10),\n",
    "    nimare.meta.kernel.ALEKernel(sample_size=20),\n",
    "]\n",
    "\n",
    "for i_kernel, kernel in enumerate(kernels):\n",
    "    ma_maps = kernel.transform(pain_dset, return_type=\"image\")\n",
    "\n",
    "    # Plot the kernel\n",
    "    plotting.plot_stat_map(\n",
    "        ma_maps[0],\n",
    "        annotate=False,\n",
    "        axes=axes[i_kernel],\n",
    "        cmap=\"Reds\",\n",
    "        cut_coords=[0, 0, -24],\n",
    "        draw_cross=False,\n",
    "        figure=fig,\n",
    "        title=type(kernel),\n",
    "    )\n",
    "\n",
    "# Show the overall figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta-analytic Estimators are initialized with parameters which determine how the Estimator will be run. For example, ALE accepts a kernel transformer (which defaults to the standard `ALEKernel`), a null method, the number of iterations used to define the null distribution, and the number of cores to be used during fitting.\n",
    "\n",
    "The Estimators also have a `fit` method, which accepts a `Dataset` object and returns a `MetaResult` object. [`MetaResult`s](https://nimare.readthedocs.io/en/latest/generated/nimare.results.MetaResult.html#nimare.results.MetaResult) link statistical image names to numpy arrays, and can be used to produce nibabel images from those arrays, as well as save the images to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.cbma.ale.ALE(null_method=\"approximate\")\n",
    "meta_results = meta.fit(pain_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(meta_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(meta_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(meta_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_img = meta_results.get_map(\"z\")\n",
    "print(type(z_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    z_img,\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple comparisons correction\n",
    "\n",
    "Most of the time, you will want to follow up your meta-analysis with some form of multiple comparisons correction. For this, NiMARE provides Corrector classes in the `correct` module. Specifically, there are two Correctors: [`FWECorrector`](https://nimare.readthedocs.io/en/latest/generated/nimare.correct.FWECorrector.html) and [`FDRCorrector`](https://nimare.readthedocs.io/en/latest/generated/nimare.correct.FDRCorrector.html). In both cases, the Corrector supports a range of naive correction options relying on [`statsmodels`' methods](https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html).\n",
    "\n",
    "In addition to generic multiple comparisons correction, the Correctors also reference algorithm-specific correction methods, such as the `montecarlo` method supported by most coordinate-based meta-analysis algorithms.\n",
    "\n",
    "Correctors are initialized with parameters, and they have a `transform` method that accepts a `MetaResult` object and returns an updated one with the corrected maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_corrector = nimare.correct.FWECorrector(\n",
    "    method=\"montecarlo\", \n",
    "    n_iters=100,\n",
    "    n_cores=1,\n",
    ")\n",
    "mc_results = mc_corrector.transform(meta_results)\n",
    "\n",
    "# Let's store the CBMA result for later\n",
    "cbma_z_img = mc_results.get_map(\"z_level-cluster_corr-FWE_method-montecarlo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mc_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(mc_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_level-cluster_corr-FWE_method-montecarlo\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    "    vmax=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a standard cluster table for the meta-analytic map using a threshold of p<0.05\n",
    "reporting.get_clusters_table(cbma_z_img, stat_threshold=1.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-based meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"z\" images are missing for some, but not all, of the studies.\n",
    "\n",
    "NiMARE's `transforms` module contains a function, `transform_images`, which can generate images from other images- as long as the right images and metadata are available. In this case, it can generate z-statistic images from t-statistic maps, combined with sample size information in the metadata. It can also generate \"varcope\" (contrast variance) images from the contrast standard error images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing images\n",
    "pain_dset.images = nimare.transforms.transform_images(\n",
    "    pain_dset.images,\n",
    "    target=\"z\",\n",
    "    masker=pain_dset.masker,\n",
    "    metadata_df=pain_dset.metadata,\n",
    ")\n",
    "pain_dset.images = nimare.transforms.transform_images(\n",
    "    pain_dset.images,\n",
    "    target=\"varcope\",\n",
    "    masker=pain_dset.masker,\n",
    "    metadata_df=pain_dset.metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_dset.images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the image types we will need for our meta-analyses, we can run a couple of image-based meta-analysis types.\n",
    "\n",
    "The `DerSimonianLaird` method uses \"beta\" and \"varcope\" images, and estimates between-study variance (a.k.a. $\\tau^2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.ibma.DerSimonianLaird()\n",
    "meta_results = meta.fit(pain_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    meta_results.get_map(\"z\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PermutedOLS` method uses z-statistic images, and relies on [nilearn's `permuted_ols`](https://nilearn.github.io/modules/generated/nilearn.mass_univariate.permuted_ols.html) tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.ibma.PermutedOLS()\n",
    "meta_results = meta.fit(pain_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    meta_results.get_map(\"z\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_corrector = nimare.correct.FWECorrector(method=\"montecarlo\", n_iters=100)\n",
    "mc_results = mc_corrector.transform(meta_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mc_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(mc_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    "    vmax=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a standard cluster table for the meta-analytic map using a threshold of p<0.05\n",
    "reporting.get_clusters_table(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    stat_threshold=1.65,\n",
    "    cluster_threshold=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to results from the SPM IBMA extension\n",
    "\n",
    "![IBMA comparison](images/ibma_comparison.png)\n",
    "\n",
    "Adapted from [Maumet & Nichols (2014)](https://www.frontiersin.org/10.3389/conf.fninf.2014.18.00025/event_abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    threshold=1.65,\n",
    "    vmax=3,\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    cbma_z_img,\n",
    "    threshold=1.65,\n",
    "    vmax=3,\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Analytic Functional Decoding\n",
    "\n",
    "Functional decoding refers to approaches which attempt to infer mental processes, tasks, etc. from imaging data. There are many approaches to functional decoding, but one set of approaches uses meta-analytic databases like Neurosynth or BrainMap, which we call \"meta-analytic functional decoding.\" For more information on functional decoding in general, read [Poldrack (2011)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3240863/).\n",
    "\n",
    "In NiMARE, we group decoding methods into three general types: discrete decoding, continuous decoding, and encoding.\n",
    "\n",
    "- **Discrete decoding methods** use a meta-analytic database and annotations of studies in that database to describe something discrete (like a region of interest) in terms of those annotations.\n",
    "\n",
    "- **Continuous decoding methods** use the same type of database to describe an unthresholded brain map in terms of the database's annotations. One example of this kind of method is the Neurosynth-based decoding available on Neurovault. In that method, the map you want to decode is correlated with Neurosynth term-specific meta-analysis maps. You end up with one correlation coefficient for each term in Neurosynth. Users generally report the top ten or so terms.\n",
    "\n",
    "- **Encoding methods** do the opposite- they take in annotations or raw text and produce a synthesized brain map. One example of a meta-analytic encoding tool is [NeuroQuery](https://neuroquery.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the continuous decoding methods available in NiMARE are too computationally intensive and time-consuming for Binder, so we will focus on discrete decoding methods.\n",
    "The two most useful discrete decoders in NiMARE are the [`BrainMapDecoder`](https://nimare.readthedocs.io/en/latest/generated/nimare.decode.discrete.BrainMapDecoder.html#nimare.decode.discrete.BrainMapDecoder) and the [`NeurosynthDecoder`](https://nimare.readthedocs.io/en/latest/generated/nimare.decode.discrete.NeurosynthDecoder.html#nimare.decode.discrete.NeurosynthDecoder). Detailed descriptions of the two approaches are available in [NiMARE's documentation](https://nimare.readthedocs.io/en/latest/methods/decoding.html#discrete-decoding), but here's the basic idea:\n",
    "\n",
    "0. A NiMARE `Dataset` must contain both annotations/labels and coordinates.\n",
    "1. A subset of studies in the `Dataset` must be selected according to some criterion, such as having at least one peak in a region of interest or having a specific label.\n",
    "2. The algorithm then compares the frequency of each label within the selected subset of studies against the frequency of other labels in that subset to calculate \"forward-inference\" posterior probability, p-value, and z-statistic.\n",
    "3. The algorithm also compares the frequency of each label within the subset of studies against the the frequency of that label in the *unselected* studies from the `Dataset` to calculate \"reverse-inference\" posterior probability, p-value, and z-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the sheer size of Neurosynth, we will only use the first 500 studies in this example\n",
    "ns_dset = ns_dset.slice(ns_dset.ids[:500])\n",
    "\n",
    "label_ids = ns_dset.get_studies_by_label(\"Neurosynth_TFIDF__amygdala\", label_threshold=0.001)\n",
    "print(f\"There are {len(label_ids)} studies in the Dataset with the 'Neurosynth_TFIDF__amygdala' label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nimare.decode.discrete.BrainMapDecoder(correction=None)\n",
    "decoder.fit(ns_dset)\n",
    "decoded_df = decoder.transform(ids=label_ids)\n",
    "decoded_df.sort_values(by=\"probReverse\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nimare.decode.discrete.NeurosynthDecoder(correction=None)\n",
    "decoder.fit(ns_dset)\n",
    "decoded_df = decoder.transform(ids=label_ids)\n",
    "decoded_df.sort_values(by=\"probReverse\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Run a MACM and Decode an ROI\n",
    "\n",
    "Remember that a MACM is a meta-analysis performed on studies which report at least one peak within a region of interest. This type of analysis is generally interpreted as a meta-analytic version of functional connectivity analysis.\n",
    "\n",
    "We will use an anterior cingulate cortex mask as our ROI, which we will use to (1) run a MACM using the (reduced) Neurosynth dataset and (2) decode the ROI using labels from Neurosynth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to prepare some things for the exercise. You just need to run these cells without editing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_FILE = op.join(DATA_DIR, \"amygdala_roi.nii.gz\")\n",
    "\n",
    "plotting.plot_roi(\n",
    "    ROI_FILE,\n",
    "    title=\"Anterior Cingular Gyrus\",\n",
    "    draw_cross=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, try to write code in each cell based on its comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, use the Dataset class's get_studies_by_mask method\n",
    "# to identify studies with at least one coordinate in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a reduced version of the Dataset including only\n",
    "# studies identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, run a meta-analysis on the reduced ROI dataset.\n",
    "# This is a MACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize, fit, and transform a Neurosynth Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
